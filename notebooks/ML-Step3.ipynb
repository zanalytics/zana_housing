{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model Building Pipeline: Feature Selection\n",
    "\n",
    "In the following videos, we will take you through a practical example of each one of the steps in the Machine Learning model building pipeline, which we described in the previous lectures. There will be a notebook for each one of the Machine Learning Pipeline steps:\n",
    "\n",
    "1. Data Analysis\n",
    "2. Feature Engineering\n",
    "3. Feature Selection\n",
    "4. Model Building\n",
    "\n",
    "**This is the notebook for step 3: Feature Selection**\n",
    "\n",
    "\n",
    "We will use the house price dataset available on [Kaggle.com](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data). See below for more details.\n",
    "\n",
    "===================================================================================================\n",
    "\n",
    "## Predicting Sale Price of Houses\n",
    "\n",
    "The aim of the project is to build a machine learning model to predict the sale price of homes based on different explanatory variables describing aspects of residential houses. \n",
    "\n",
    "### Why is this important? \n",
    "\n",
    "Predicting house prices is useful to identify fruitful investments, or to determine whether the price advertised for a house is over or under-estimated.\n",
    "\n",
    "### What is the objective of the machine learning model?\n",
    "\n",
    "We aim to minimise the difference between the real price and the price estimated by our model. We will evaluate model performance using the mean squared error (mse) and the root squared of the mean squared error (rmse).\n",
    "\n",
    "### How do I download the dataset?\n",
    "\n",
    "To download the House Price dataset go this website:\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
    "\n",
    "Scroll down to the bottom of the page, and click on the link 'train.csv', and then click the 'download' blue button towards the right of the screen, to download the dataset. Rename the file as 'houseprice.csv' and save it to a directory of your choice.\n",
    "\n",
    "**Note the following:**\n",
    "-  You need to be logged in to Kaggle in order to download the datasets.\n",
    "-  You need to accept the terms and conditions of the competition to download the dataset\n",
    "-  If you save the file to the same directory where you saved this jupyter notebook, then you can run the code as it is written here.\n",
    "\n",
    "===================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Prices dataset: Feature Selection\n",
    "\n",
    "In the following cells, we will select a group of variables, the most predictive ones, to build our machine learning model. \n",
    "\n",
    "### Why do we select variables?\n",
    "\n",
    "- For production: Fewer variables mean smaller client input requirements (e.g. customers filling out a form on a website or mobile app), and hence less code for error handling. This reduces the chances of introducing bugs.\n",
    "\n",
    "- For model performance: Fewer variables mean simpler, more interpretable, better generalizing models\n",
    "\n",
    "\n",
    "**We will select variables using the Lasso regression: Lasso has the property of setting the coefficient of non-informative variables to zero. This way we can identify those variables and remove them from our final model.**\n",
    "\n",
    "\n",
    "### Setting the seed\n",
    "\n",
    "It is important to note, that we are engineering variables and pre-processing data with the idea of deploying the model. Therefore, from now on, for each step that includes some element of randomness, it is extremely important that we **set the seed**. This way, we can obtain reproducibility between our research and our development code.\n",
    "\n",
    "This is perhaps one of the most important lessons that you need to take away from this course: **Always set the seeds**.\n",
    "\n",
    "Let's go ahead and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  postcode  primary_address  secondary_address  street  latitude  \\\n",
       "0   0       0.0         0.384615                0.0     0.0  0.297610   \n",
       "1   0       0.0         0.846154                1.0     0.0  0.240519   \n",
       "2   0       0.0         0.461538                0.0     0.0  0.420328   \n",
       "3   0       0.0         0.923077                0.0     0.0  0.470684   \n",
       "4   0       0.0         0.153846                0.0     0.0  0.443657   \n",
       "\n",
       "   longitude  grid_ref    county  district  ward  district_code  ward_code  \\\n",
       "0   0.708851       0.0  0.951220  0.666667   0.0       0.666667        0.0   \n",
       "1   0.738338       0.0  1.000000  0.666667   0.0       0.666667        0.0   \n",
       "2   0.552343       0.0  0.292683  0.666667   0.0       0.666667        0.0   \n",
       "3   0.716527       0.0  0.146341  0.666667   0.0       0.666667        0.0   \n",
       "4   0.597107       0.0  0.414634  0.666667   0.0       0.666667        0.0   \n",
       "\n",
       "   county_code  constituency    region  london_zone  \\\n",
       "0     0.951220           0.0  0.777778     1.000000   \n",
       "1     1.000000           0.0  1.000000     0.666667   \n",
       "2     0.292683           0.0  0.555556     1.000000   \n",
       "3     0.146341           0.0  0.444444     1.000000   \n",
       "4     0.414634           0.0  0.444444     1.000000   \n",
       "\n",
       "   middle_layer_super_output_area  postcode_area  postcode_district  quality  \\\n",
       "0                             0.0       0.522727                0.0      0.0   \n",
       "1                             0.0       0.522727                0.0      0.0   \n",
       "2                             0.0       0.500000                0.0      0.0   \n",
       "3                             0.0       0.340909                0.0      0.0   \n",
       "4                             0.0       0.477273                0.0      0.0   \n",
       "\n",
       "   user_type  last_updated  nearest_station  distance_to_station  \\\n",
       "0        0.0           0.0              0.0             0.689014   \n",
       "1        0.0           0.0              0.0            -0.375478   \n",
       "2        0.0           0.0              0.0             1.025923   \n",
       "3        0.0           0.0              0.0             2.408421   \n",
       "4        0.0           0.0              0.0             1.169875   \n",
       "\n",
       "   postcode_area.1  postcode_district.1  police_force  water_company  \\\n",
       "0         0.522727                  0.0      0.947368       0.888889   \n",
       "1         0.522727                  0.0      1.000000       0.944444   \n",
       "2         0.500000                  0.0      0.368421       0.277778   \n",
       "3         0.340909                  0.0      0.263158       0.333333   \n",
       "4         0.477273                  0.0      0.500000       0.277778   \n",
       "\n",
       "   plus_code  average_income  sewage_company  travel_to_work_area  \\\n",
       "0        0.0        0.626321             1.0             0.708333   \n",
       "1        0.0        0.582384             1.0             1.000000   \n",
       "2        0.0        0.591111             0.4             0.333333   \n",
       "3        0.0        0.680413             0.4             0.375000   \n",
       "4        0.0        0.541677             0.4             0.458333   \n",
       "\n",
       "   rural_urban  altitude  region_name  area_code  adjusted_price  type_D  \\\n",
       "0     0.666667  0.269953     0.666667   0.666667       12.926339     0.0   \n",
       "1     0.666667  0.110329     0.666667   0.666667       12.416423     0.0   \n",
       "2     0.333333  0.298122     0.666667   0.666667       12.862997     1.0   \n",
       "3     1.000000  0.028169     0.666667   0.666667       13.213782     1.0   \n",
       "4     0.500000  0.178404     0.666667   0.666667       12.209063     0.0   \n",
       "\n",
       "   type_F  type_O  type_S  type_T  land_F  new_build_Y  \n",
       "0     0.0     0.0     0.0     1.0     1.0          0.0  \n",
       "1     1.0     0.0     0.0     0.0     0.0          0.0  \n",
       "2     0.0     0.0     0.0     0.0     1.0          0.0  \n",
       "3     0.0     0.0     0.0     0.0     1.0          0.0  \n",
       "4     0.0     0.0     1.0     0.0     1.0          0.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>postcode</th>\n      <th>primary_address</th>\n      <th>secondary_address</th>\n      <th>street</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>grid_ref</th>\n      <th>county</th>\n      <th>district</th>\n      <th>ward</th>\n      <th>district_code</th>\n      <th>ward_code</th>\n      <th>county_code</th>\n      <th>constituency</th>\n      <th>region</th>\n      <th>london_zone</th>\n      <th>middle_layer_super_output_area</th>\n      <th>postcode_area</th>\n      <th>postcode_district</th>\n      <th>quality</th>\n      <th>user_type</th>\n      <th>last_updated</th>\n      <th>nearest_station</th>\n      <th>distance_to_station</th>\n      <th>postcode_area.1</th>\n      <th>postcode_district.1</th>\n      <th>police_force</th>\n      <th>water_company</th>\n      <th>plus_code</th>\n      <th>average_income</th>\n      <th>sewage_company</th>\n      <th>travel_to_work_area</th>\n      <th>rural_urban</th>\n      <th>altitude</th>\n      <th>region_name</th>\n      <th>area_code</th>\n      <th>adjusted_price</th>\n      <th>type_D</th>\n      <th>type_F</th>\n      <th>type_O</th>\n      <th>type_S</th>\n      <th>type_T</th>\n      <th>land_F</th>\n      <th>new_build_Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.384615</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.297610</td>\n      <td>0.708851</td>\n      <td>0.0</td>\n      <td>0.951220</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.951220</td>\n      <td>0.0</td>\n      <td>0.777778</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.522727</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.689014</td>\n      <td>0.522727</td>\n      <td>0.0</td>\n      <td>0.947368</td>\n      <td>0.888889</td>\n      <td>0.0</td>\n      <td>0.626321</td>\n      <td>1.0</td>\n      <td>0.708333</td>\n      <td>0.666667</td>\n      <td>0.269953</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>12.926339</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.846154</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.240519</td>\n      <td>0.738338</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.522727</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.375478</td>\n      <td>0.522727</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.944444</td>\n      <td>0.0</td>\n      <td>0.582384</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>0.110329</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>12.416423</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.461538</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.420328</td>\n      <td>0.552343</td>\n      <td>0.0</td>\n      <td>0.292683</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.292683</td>\n      <td>0.0</td>\n      <td>0.555556</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.025923</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.368421</td>\n      <td>0.277778</td>\n      <td>0.0</td>\n      <td>0.591111</td>\n      <td>0.4</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.298122</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>12.862997</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.923077</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.470684</td>\n      <td>0.716527</td>\n      <td>0.0</td>\n      <td>0.146341</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.146341</td>\n      <td>0.0</td>\n      <td>0.444444</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.340909</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.408421</td>\n      <td>0.340909</td>\n      <td>0.0</td>\n      <td>0.263158</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.680413</td>\n      <td>0.4</td>\n      <td>0.375000</td>\n      <td>1.000000</td>\n      <td>0.028169</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>13.213782</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.153846</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.443657</td>\n      <td>0.597107</td>\n      <td>0.0</td>\n      <td>0.414634</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.414634</td>\n      <td>0.0</td>\n      <td>0.444444</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.477273</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.169875</td>\n      <td>0.477273</td>\n      <td>0.0</td>\n      <td>0.500000</td>\n      <td>0.277778</td>\n      <td>0.0</td>\n      <td>0.541677</td>\n      <td>0.4</td>\n      <td>0.458333</td>\n      <td>0.500000</td>\n      <td>0.178404</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>12.209063</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# load the train and test set with the engineered variables\n",
    "\n",
    "# we built and saved these datasets in the previous lecture.\n",
    "# If you haven't done so, go ahead and check the previous notebook\n",
    "# to find out how to create these datasets\n",
    "\n",
    "X_train = pd.read_csv('../data/processed/xtrain.csv')\n",
    "X_test = pd.read_csv('../data/processed/xtest.csv')\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture the target (remember that the target is log transformed)\n",
    "y_train = X_train['adjusted_price']\n",
    "y_test = X_test['adjusted_price']\n",
    "\n",
    "# drop unnecessary variables from our training and testing sets\n",
    "X_train.drop(['id', 'adjusted_price'], axis=1, inplace=True)\n",
    "X_test.drop(['id', 'adjusted_price'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "Let's go ahead and select a subset of the most predictive features. There is an element of randomness in the Lasso regression, so remember to set the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f2546dab28c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best alpha using built-in LassoCV: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best score using built-in LassoCV: %f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                                   \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                                   copy=copy_X)\n\u001b[0;32m-> 1213\u001b[0;31m             X, y = self._validate_data(X, y,\n\u001b[0m\u001b[1;32m   1214\u001b[0m                                        validate_separately=(check_X_params,\n\u001b[1;32m   1215\u001b[0m                                                             check_y_params))\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0;31m# :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "\n",
    "reg = LassoCV()\n",
    "X = X_train\n",
    "y = y_train\n",
    "reg.fit(X, y)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\n",
    "coef = pd.Series(reg.coef_, index = X.columns)\n",
    "\n",
    "\n",
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "\n",
    "\n",
    "imp_coef = coef.sort_values()\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=Lasso(alpha=0.005, random_state=0))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# We will do the model fitting and feature selection\n",
    "# altogether in a few lines of code\n",
    "\n",
    "# first, we specify the Lasso Regression model, and we\n",
    "# select a suitable alpha (equivalent of penalty).\n",
    "# The bigger the alpha the less features that will be selected.\n",
    "\n",
    "# Then we use the selectFromModel object from sklearn, which\n",
    "# will select automatically the features which coefficients are non-zero\n",
    "\n",
    "# remember to set the seed, the random state in this function\n",
    "sel_ = SelectFromModel(Lasso(alpha=0.005, random_state=0))\n",
    "\n",
    "# train Lasso model and select features\n",
    "sel_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "       False, False, False,  True, False,  True,  True, False,  True,\n",
       "       False,  True,  True, False, False,  True,  True, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# let's visualise those features that were selected.\n",
    "# (selected features marked with True)\n",
    "\n",
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total features: 46\nselected features: 32\nfeatures with coefficients shrank to zero: 14\n"
     ]
    }
   ],
   "source": [
    "# let's print the number of total and selected features\n",
    "\n",
    "# this is how we can make a list of the selected features\n",
    "selected_feats = X_train.columns[(sel_.get_support())]\n",
    "\n",
    "# let's print some stats\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feats)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['primary_address', 'secondary_address', 'street', 'latitude',\n",
       "       'longitude', 'county', 'district', 'county_code', 'region',\n",
       "       'london_zone', 'postcode_area', 'quality', 'user_type',\n",
       "       'distance_to_station', 'postcode_area.1', 'police_force',\n",
       "       'water_company', 'average_income', 'sewage_company',\n",
       "       'travel_to_work_area', 'rural_urban', 'altitude', 'region_name',\n",
       "       'type_D', 'type_F', 'type_O', 'type_S', 'type_T', 'land_F', 'land_L',\n",
       "       'land_U', 'new_build_N'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# print the selected features\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the selected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['primary_address', 'secondary_address', 'street', 'latitude',\n",
       "       'longitude', 'county', 'district', 'county_code', 'region',\n",
       "       'london_zone', 'postcode_area', 'quality', 'user_type',\n",
       "       'distance_to_station', 'postcode_area.1', 'police_force',\n",
       "       'water_company', 'average_income', 'sewage_company',\n",
       "       'travel_to_work_area', 'rural_urban', 'altitude', 'region_name',\n",
       "       'type_D', 'type_F', 'type_O', 'type_S', 'type_T', 'land_F', 'land_L',\n",
       "       'land_U', 'new_build_N'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# this is an alternative way of identifying the selected features\n",
    "# based on the non-zero regularisation coefficients:\n",
    "\n",
    "selected_feats = X_train.columns[(sel_.estimator_.coef_ != 0).ravel().tolist()] \n",
    "\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(selected_feats).to_csv('../data/processed/selected_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That is all for this notebook. In the next video, we will go ahead and build the final model using the selected features. See you then!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "583px",
    "left": "0px",
    "right": "1324px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}